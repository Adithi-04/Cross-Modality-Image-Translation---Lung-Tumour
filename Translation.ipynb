{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# =======================\n",
    "# GPU Configuration (CRITICAL!)\n",
    "# =======================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU Found: {tf.config.list_physical_devices('GPU')}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Enable mixed precision for faster training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "print(\"‚úÖ Mixed precision enabled\")\n",
    "\n",
    "# Enable XLA for faster execution\n",
    "tf.config.optimizer.set_jit(True)\n",
    "print(\"‚úÖ XLA compilation enabled\")\n",
    "\n",
    "# =======================\n",
    "# Parameters (OPTIMIZED!)\n",
    "# =======================\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 1   # Keeping batch size at 1 as requested\n",
    "EPOCHS = 50\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "OUTPUT_CHANNELS = 1\n",
    "\n",
    "# =======================\n",
    "# Dataset Loader (OPTIMIZED!)\n",
    "# =======================\n",
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = (image / 127.5) - 1.0  # normalize [-1, 1]\n",
    "    return image\n",
    "\n",
    "def make_dataset(folder):\n",
    "    paths = [os.path.join(folder, f) for f in sorted(os.listdir(folder))]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    dataset = dataset.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache()  # ‚Üê ADDED: Cache in memory!\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat()  # ‚Üê ADDED: Repeat for multiple epochs\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "trainA = make_dataset(\"/content/dataset/dataset/trainA\")  # CT\n",
    "trainB = make_dataset(\"/content/dataset/dataset/trainB\")  # PET\n",
    "\n",
    "print(\"‚úÖ Datasets loaded and optimized\")\n",
    "\n",
    "# =======================\n",
    "# Generator (ResNet-based)\n",
    "# =======================\n",
    "def resnet_block(x, filters, size=3):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    y = layers.Conv2D(filters, size, padding='same', kernel_initializer=initializer)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(filters, size, padding='same', kernel_initializer=initializer)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    return layers.Add()([x, y])\n",
    "\n",
    "def Generator():\n",
    "    inputs = layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 1])\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    # c7s1-64\n",
    "    x = layers.Conv2D(64, 7, strides=1, padding='same', kernel_initializer=initializer)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # d128, d256\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 6 resnet blocks\n",
    "    for _ in range(6):\n",
    "        x = resnet_block(x, 256)\n",
    "\n",
    "    # u128, u64\n",
    "    x = layers.Conv2DTranspose(128, 3, strides=2, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # c7s1-1\n",
    "    x = layers.Conv2D(OUTPUT_CHANNELS, 7, strides=1, padding='same', kernel_initializer=initializer, activation='tanh')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# =======================\n",
    "# Discriminator (PatchGAN)\n",
    "# =======================\n",
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inp = layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 1])\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same', kernel_initializer=initializer)(inp)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, 4, strides=1, padding='same', kernel_initializer=initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(1, 4, strides=1, padding='same', kernel_initializer=initializer)(x)\n",
    "    return tf.keras.Model(inputs=inp, outputs=x)\n",
    "\n",
    "# =======================\n",
    "# Instantiate models\n",
    "# =======================\n",
    "print(\"Building models...\")\n",
    "G = Generator()      # CT ‚Üí PET\n",
    "F = Generator()      # PET ‚Üí CT\n",
    "D_CT = Discriminator()\n",
    "D_PET = Discriminator()\n",
    "print(\"‚úÖ Models built\")\n",
    "\n",
    "# =======================\n",
    "# Loss Functions (FIXED for Mixed Precision)\n",
    "# =======================\n",
    "loss_obj = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def discriminator_loss(real, generated):\n",
    "    # Inputs (real, generated) are Discriminator outputs, which should be float32 due to mixed precision policy\n",
    "    # if the last layer is correctly set, but casting doesn't hurt.\n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_loss = (real_loss + generated_loss) * 0.5\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(generated):\n",
    "    # Input 'generated' is Discriminator output (which should ideally be float32)\n",
    "    return loss_obj(tf.ones_like(generated), generated)\n",
    "\n",
    "LAMBDA = 10\n",
    "\n",
    "def cycle_loss(real_image, cycled_image):\n",
    "    # CRITICAL FIX: Cast both tensors to float32 before subtraction\n",
    "    real_image_f32 = tf.cast(real_image, tf.float32)\n",
    "    cycled_image_f32 = tf.cast(cycled_image, tf.float32)\n",
    "\n",
    "    return LAMBDA * tf.reduce_mean(tf.abs(real_image_f32 - cycled_image_f32))\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    # CRITICAL FIX: Cast both tensors to float32 before subtraction\n",
    "    real_image_f32 = tf.cast(real_image, tf.float32)\n",
    "    same_image_f32 = tf.cast(same_image, tf.float32)\n",
    "\n",
    "    return LAMBDA * 0.5 * tf.reduce_mean(tf.abs(real_image_f32 - same_image_f32))\n",
    "\n",
    "# =======================\n",
    "# Optimizers (with mixed precision)\n",
    "# =======================\n",
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "# Wrap optimizers for mixed precision\n",
    "generator_g_optimizer = mixed_precision.LossScaleOptimizer(generator_g_optimizer)\n",
    "generator_f_optimizer = mixed_precision.LossScaleOptimizer(generator_f_optimizer)\n",
    "discriminator_x_optimizer = mixed_precision.LossScaleOptimizer(discriminator_x_optimizer)\n",
    "discriminator_y_optimizer = mixed_precision.LossScaleOptimizer(discriminator_y_optimizer)\n",
    "\n",
    "# =======================\n",
    "# Checkpoints\n",
    "# =======================\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(G=G,\n",
    "                           F=F,\n",
    "                           D_CT=D_CT,\n",
    "                           D_PET=D_PET,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# =======================\n",
    "# Training Step (FIXED for MODERN KERAS API)\n",
    "# =======================\n",
    "@tf.function\n",
    "def train_step(real_CT, real_PET):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "        # --- Forward Pass ---\n",
    "        # Generator forward (G: CT -> PET, F: PET -> CT)\n",
    "        fake_PET = G(real_CT, training=True)\n",
    "        cycled_CT = F(fake_PET, training=True)\n",
    "\n",
    "        fake_CT = F(real_PET, training=True)\n",
    "        cycled_PET = G(fake_CT, training=True)\n",
    "\n",
    "        # Identity mapping\n",
    "        same_CT = F(real_CT, training=True)\n",
    "        same_PET = G(real_PET, training=True)\n",
    "\n",
    "        # Discriminator outputs\n",
    "        disc_real_CT = D_CT(real_CT, training=True)\n",
    "        disc_real_PET = D_PET(real_PET, training=True)\n",
    "        disc_fake_CT = D_CT(fake_CT, training=True)\n",
    "        disc_fake_PET = D_PET(fake_PET, training=True)\n",
    "\n",
    "        # --- Loss Calculations (These are the UNSEALED losses) ---\n",
    "        gen_g_loss = generator_loss(disc_fake_PET) + cycle_loss(real_CT, cycled_CT) + identity_loss(real_PET, same_PET)\n",
    "        gen_f_loss = generator_loss(disc_fake_CT) + cycle_loss(real_PET, cycled_PET) + identity_loss(real_CT, same_CT)\n",
    "\n",
    "        # Discriminator losses\n",
    "        disc_CT_loss = discriminator_loss(disc_real_CT, disc_fake_CT)\n",
    "        disc_PET_loss = discriminator_loss(disc_real_PET, disc_fake_PET)\n",
    "\n",
    "        # ----------------------------------------------------------------------\n",
    "        # REMOVED: All manual loss scaling (e.g., generator_g_optimizer.get_scaled_loss)\n",
    "        # ----------------------------------------------------------------------\n",
    "\n",
    "    # Gradients (Calculate on the UNSEALED loss)\n",
    "    # The GradientTape will use float32 for the loss calculation due to policy/casting,\n",
    "    # but the subsequent apply_gradients call handles the mixed precision logic.\n",
    "    gradients_g = tape.gradient(gen_g_loss, G.trainable_variables)\n",
    "    gradients_f = tape.gradient(gen_f_loss, F.trainable_variables)\n",
    "    gradients_d_CT = tape.gradient(disc_CT_loss, D_CT.trainable_variables)\n",
    "    gradients_d_PET = tape.gradient(disc_PET_loss, D_PET.trainable_variables)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # REMOVED: All manual gradient unscaling (e.g., generator_g_optimizer.get_unscaled_gradients)\n",
    "    # ----------------------------------------------------------------------\n",
    "\n",
    "    # Apply gradients\n",
    "    # The LossScaleOptimizer instance (e.g., generator_g_optimizer) handles\n",
    "    # scaling, unscaling, and applying updates internally.\n",
    "    generator_g_optimizer.apply_gradients(zip(gradients_g, G.trainable_variables))\n",
    "    generator_f_optimizer.apply_gradients(zip(gradients_f, F.trainable_variables))\n",
    "    discriminator_x_optimizer.apply_gradients(zip(gradients_d_CT, D_CT.trainable_variables))\n",
    "    discriminator_y_optimizer.apply_gradients(zip(gradients_d_PET, D_PET.trainable_variables))\n",
    "\n",
    "    return gen_g_loss, gen_f_loss, disc_CT_loss, disc_PET_loss\n",
    "\n",
    "def generate_images(G, F, real_CT, real_PET):\n",
    "    \"\"\"\n",
    "    Visualizes CT ‚Üí PET ‚Üí CT and PET ‚Üí CT ‚Üí PET\n",
    "    \"\"\"\n",
    "    # Generate images\n",
    "    fake_PET = G(real_CT, training=False)\n",
    "    cycled_CT = F(fake_PET, training=False)\n",
    "\n",
    "    fake_CT = F(real_PET, training=False)\n",
    "    cycled_PET = G(fake_CT, training=False)\n",
    "\n",
    "    # Convert [-1,1] to [0,1] for visualization\n",
    "    def denorm(img):\n",
    "        return (img + 1) / 2\n",
    "\n",
    "    real_CT = denorm(real_CT)\n",
    "    real_PET = denorm(real_PET)\n",
    "    fake_PET = denorm(fake_PET)\n",
    "    cycled_CT = denorm(cycled_CT)\n",
    "    fake_CT = denorm(fake_CT)\n",
    "    cycled_PET = denorm(cycled_PET)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Display first batch image\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.title(\"Real CT\")\n",
    "    plt.imshow(real_CT[0,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.title(\"Fake PET (CT ‚Üí PET)\")\n",
    "    plt.imshow(fake_PET[0,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.title(\"Cycled CT (CT ‚Üí PET ‚Üí CT)\")\n",
    "    plt.imshow(cycled_CT[0,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.title(\"Real PET\")\n",
    "    plt.imshow(real_PET[0,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.title(\"Fake CT (PET ‚Üí CT)\")\n",
    "    plt.imshow(fake_CT[0,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.title(\"Cycled PET (PET ‚Üí CT ‚Üí PET)\")\n",
    "    plt.imshow(cycled_PET[0,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output_epoch_{epoch+1}.png')\n",
    "    # plt.close() # Removed plt.close()\n",
    "    plt.show()\n",
    "\n",
    "# =======================\n",
    "# Training Loop (OPTIMIZED with progress bar)\n",
    "# =======================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Starting Training: {EPOCHS} epochs, batch size {BATCH_SIZE}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "STEPS_PER_EPOCH = 1400 // BATCH_SIZE  # 1400 images\n",
    "\n",
    "dataset = tf.data.Dataset.zip((trainA, trainB))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    # Progress bar for each epoch\n",
    "    with tqdm(total=STEPS_PER_EPOCH, desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for step, (real_CT, real_PET) in enumerate(dataset.take(STEPS_PER_EPOCH)):\n",
    "            gen_g_loss, gen_f_loss, disc_CT_loss, disc_PET_loss = train_step(real_CT, real_PET)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "            # Update progress bar with losses every 50 steps\n",
    "            if step % 50 == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'G_loss': f'{gen_g_loss:.2f}',\n",
    "                    'F_loss': f'{gen_f_loss:.2f}',\n",
    "                    'D_CT': f'{disc_CT_loss:.2f}',\n",
    "                    'D_PET': f'{disc_PET_loss:.2f}'\n",
    "                })\n",
    "\n",
    "    epoch_time = time.time() - start\n",
    "    print(f\"‚úÖ Epoch {epoch+1} completed in {epoch_time/60:.2f} minutes\")\n",
    "\n",
    "    # Save checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        ckpt_manager.save()\n",
    "        print(f\"üíæ Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Visualize after each epoch (moved outside the if condition)\n",
    "    for real_CT_batch, real_PET_batch in dataset.take(1):\n",
    "        generate_images(G, F, real_CT_batch, real_PET_batch)\n",
    "        print(f\"üñºÔ∏è  Sample images saved\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ Training Complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
